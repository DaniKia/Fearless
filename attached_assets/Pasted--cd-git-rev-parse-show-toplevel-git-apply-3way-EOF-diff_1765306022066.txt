 (cd "$(git rev-parse --show-toplevel)" && git apply --3way <<'EOF' 
diff --git a/modules/speaker_identifier.py b/modules/speaker_identifier.py
index 75fc67e6c60e9a8a125cacf8d82e3a4a6c9ea4a8..81a5eb4fe43f5555cc2962bf274a126cefcbd147 100644
--- a/modules/speaker_identifier.py
+++ b/modules/speaker_identifier.py
@@ -77,78 +77,98 @@ class SpeakerIdentifier:
                 if embedding.ndim > 1:
                     embedding = embedding.flatten()
             
             return embedding
             
         except Exception as e:
             print(f"Error extracting embedding from {audio_path}: {e}")
             return None
     
     def enroll_speakers(self, speaker_files_dict, save_path=None):
         """
         Enroll speakers by creating averaged embeddings from their audio files.
         Uses GPU batch processing for faster enrollment.
         
         Args:
             speaker_files_dict: Dictionary mapping speaker_id to list of audio paths
             save_path: Path to save the speaker database (optional)
             
         Returns:
             Dictionary mapping speaker_id to averaged embedding
         """
         if self.model is None:
             self.load_model()
         
         speaker_database = {}
+        # Track the speakers we have already processed so we can skip them when
+        # resuming enrollment from a partially-complete database
+        processed_speakers = set()
+
+        if save_path and os.path.exists(save_path):
+            print(f"Existing database found at {save_path}. Resuming enrollment...")
+            if self.load_database(save_path):
+                speaker_database = self.speaker_database or {}
+                processed_speakers = set(speaker_database.keys())
+            else:
+                print("Warning: Failed to load existing database. Starting fresh enrollment.")
+                speaker_database = {}
+
+        self.speaker_database = speaker_database
+
         total_speakers = len(speaker_files_dict)
         total_files = sum(len(files) for files in speaker_files_dict.values())
+        processed_files = sum(
+            len(files) for speaker_id, files in speaker_files_dict.items()
+            if speaker_id in processed_speakers
+        )
         
         print(f"\n{'='*60}")
         print(f"Enrolling {total_speakers} speakers from {total_files} audio files")
         print(f"Using batch size: {self.batch_size}")
         print(f"{'='*60}\n")
         
         speaker_count = 0
-        with tqdm(total=total_files, desc="Processing audio files", unit="file") as pbar:
+        with tqdm(total=total_files, desc="Processing audio files", unit="file", initial=processed_files) as pbar:
             for speaker_id, audio_files in speaker_files_dict.items():
                 speaker_count += 1
                 num_files = len(audio_files)
                 pbar.set_description(f"[{speaker_count}/{total_speakers}] {speaker_id} ({num_files} files)")
-                
+
+                if speaker_id in processed_speakers:
+                    continue
+
                 embeddings = self._process_files_in_batches(audio_files, pbar)
-                
+
                 if embeddings:
                     avg_embedding = np.mean(embeddings, axis=0)
                     speaker_database[speaker_id] = avg_embedding
+                    self.speaker_database = speaker_database
+                    if save_path:
+                        self.save_database(save_path)
                 else:
                     print(f"\nWarning: No valid embeddings for speaker {speaker_id}")
-        
-        self.speaker_database = speaker_database
-        
-        if save_path:
-            self.save_database(save_path)
-        
+
         print(f"\n{'='*60}")
         print(f"Enrollment complete!")
         print(f"Enrolled {len(speaker_database)} speakers")
         print(f"{'='*60}\n")
         
         return speaker_database
     
     def _process_files_in_batches(self, audio_files, pbar):
         """
         Process audio files in batches using GPU batch processing.
         
         Args:
             audio_files: List of audio file paths
             pbar: Progress bar to update
             
         Returns:
             List of embeddings
         """
         if self.model is None:
             self.load_model()
         
         all_embeddings = []
         
         for i in range(0, len(audio_files), self.batch_size):
             batch_files = audio_files[i:i + self.batch_size]
 
EOF
)