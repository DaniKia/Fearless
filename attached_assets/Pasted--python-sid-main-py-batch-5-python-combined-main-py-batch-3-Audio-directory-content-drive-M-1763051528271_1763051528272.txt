!python sid_main.py --batch 5!python combined_main.py --batch 3

 
Audio directory: /content/drive/MyDrive/Fearless_Steps_Challenge_Phase3/FSC_P3_Train_Dev/Audio/Segments/SID/Dev
Label directory: /content/drive/MyDrive/Fearless_Steps_Challenge_Phase3/FSC_P3_Train_Dev/Transcripts/SID
Loaded 6373 SID labels from Dev dataset

Processing 5 files...

Loaded speaker database with 218 speakers
/usr/local/lib/python3.12/dist-packages/speechbrain/utils/torch_audio_backend.py:57: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. 
  available_backends = torchaudio.list_audio_backends()
/content/Fearless/Fearless/Fearless/Fearless/modules/speaker_identifier.py:37: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0
  from speechbrain.pretrained import EncoderClassifier
Loading speaker embedding model: speechbrain/spkrec-ecapa-voxceleb
Using device: cuda
/usr/local/lib/python3.12/dist-packages/speechbrain/utils/torch_audio_backend.py:57: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. 
  available_backends = torchaudio.list_audio_backends()
/usr/local/lib/python3.12/dist-packages/speechbrain/utils/autocast.py:188: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  wrapped_fwd = torch.cuda.amp.custom_fwd(fwd, cast_inputs=cast_inputs)
Model loaded successfully!
Traceback (most recent call last):
  File "/content/Fearless/Fearless/Fearless/Fearless/sid_main.py", line 215, in <module>
    main()
  File "/content/Fearless/Fearless/Fearless/Fearless/sid_main.py", line 212, in main
    identify_batch(audio_dir, label_dir, limit=args.batch, dataset=args.dataset)
  File "/content/Fearless/Fearless/Fearless/Fearless/sid_main.py", line 115, in identify_batch
    result = identifier.identify_speaker(audio_path, top_k=1)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/content/Fearless/Fearless/Fearless/Fearless/modules/speaker_identifier.py", line 252, in identify_speaker
    similarity = self._cosine_similarity(test_embedding, speaker_embedding)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/content/Fearless/Fearless/Fearless/Fearless/modules/speaker_identifier.py", line 264, in _cosine_similarity
    dot_product = np.dot(vec1, vec2)
                  ^^^^^^^^^^^^^^^^^^
ValueError: shapes (192,) and (1,192) not aligned: 192 (dim 0) != 1 (dim 0)

============================================================
Combined ASR + SID Pipeline - Dev Dataset
============================================================
Audio directory: /content/drive/MyDrive/Fearless_Steps_Challenge_Phase3/FSC_P3_Train_Dev/Audio/Segments/ASR_track2/Dev
Transcript directory: /content/drive/MyDrive/Fearless_Steps_Challenge_Phase3/FSC_P3_Train_Dev/Transcripts/ASR_track2/Dev
Label directory: /content/drive/MyDrive/Fearless_Steps_Challenge_Phase3/FSC_P3_Train_Dev/Transcripts/SID
Loaded 9203 transcripts from Dev dataset
Loaded speaker database with 218 speakers

Processing 3 files...

Loaded 6373 SID labels from Dev dataset
Warning: No SID label found for fsc_p3_ASR_track2_dev_0001.wav (ID: fsc_p3_ASR_track2_dev_0001)
Loading Whisper model: tiny.en (FP16 on cuda)...
100%|██████████████████████████████████████| 72.1M/72.1M [00:00<00:00, 105MiB/s]
Model loaded successfully
Transcribing: /content/drive/MyDrive/Fearless_Steps_Challenge_Phase3/FSC_P3_Train_Dev/Audio/Segments/ASR_track2/Dev/fsc_p3_ASR_track2_dev_0001.wav
  0% 0/466 [00:00<?, ?frames/s]

================================================================================
File: fsc_p3_ASR_track2_dev_0001.wav
================================================================================
Reference: ROG AND WED LIKE UH ZERO AND FOUR ONES [unk]
Whisper  : 
Traceback (most recent call last):
  File "/content/Fearless/Fearless/Fearless/Fearless/combined_main.py", line 267, in <module>
    main()
  File "/content/Fearless/Fearless/Fearless/Fearless/combined_main.py", line 257, in main
    process_batch(
  File "/content/Fearless/Fearless/Fearless/Fearless/combined_main.py", line 156, in process_batch
    wer, cer = calculate_wer(reference_transcript, hypothesis_transcript['text'])
    ^^^^^^^^
TypeError: cannot unpack non-iterable float object